#!/usr/bin/env python3
"""
PRDå“è³ªé©—è­‰è…³æœ¬
ç”¨æ–¼é©—è­‰æ‰€æœ‰PRDæ–‡ä»¶æ˜¯å¦ç¬¦åˆæ¨™æº–æ ¼å¼è¦æ±‚
"""

import os
import re
import yaml
import json
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from datetime import datetime
import sys

class PRDValidator:
    """PRDæ–‡ä»¶é©—è­‰å™¨"""
    
    def __init__(self, prd_dir: str = "PRD"):
        self.prd_dir = Path(prd_dir)
        self.validation_results = []
        self.total_checks = 0
        self.passed_checks = 0
        
        # å®šç¾©å¿…å¡«æ¬„ä½
        self.required_fields = {
            'module_info': [
                'æ¨¡çµ„ä»£ç¢¼', 'æ¨¡çµ„åç¨±', 'è² è²¬äºº', 
                'æœ€å¾Œæ›´æ–°', 'ç‰ˆæœ¬'
            ],
            'fr_fields': [
                'æ¢ä»¶/è§¸ç™¼', 'è¡Œç‚º', 'è³‡æ–™è¼¸å…¥', 
                'è³‡æ–™è¼¸å‡º', 'UIåæ‡‰', 'ä¾‹å¤–è™•ç†', 'å„ªå…ˆç´š'
            ],
            'api_fields': [
                'API ç«¯é»', 'è«‹æ±‚/å›æ‡‰', 'æ•¸æ“šæ¨¡å‹', 
                'æ¬Šé™è¦æ±‚', 'èªè­‰æ–¹å¼'
            ]
        }
        
        # FR-IDæ ¼å¼æ­£å‰‡è¡¨é”å¼
        self.fr_id_pattern = re.compile(
            r'^FR-[A-Z]{2,4}(-[A-Z]{2,5})*-\d{3}$'
        )
        
        # ç‹€æ…‹æ¨™è¨˜
        self.valid_statuses = ['ğŸ”´ æœªé–‹å§‹', 'ğŸŸ¡ é–‹ç™¼ä¸­', 'âœ… å®Œæˆ', 'âšª è¦åŠƒä¸­']
        
    def validate_prd_file(self, file_path: Path) -> Dict:
        """é©—è­‰å–®å€‹PRDæ–‡ä»¶"""
        result = {
            'file': str(file_path),
            'module': file_path.parent.name,
            'checks': {},
            'errors': [],
            'warnings': [],
            'score': 0
        }
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # 1. æª¢æŸ¥æ¨¡çµ„è³‡è¨Š
            result['checks']['module_info'] = self._check_module_info(content)
            
            # 2. æª¢æŸ¥FR-IDæ ¼å¼
            result['checks']['fr_ids'] = self._check_fr_ids(content)
            
            # 3. æª¢æŸ¥åŠŸèƒ½éœ€æ±‚å®Œæ•´æ€§
            result['checks']['fr_completeness'] = self._check_fr_completeness(content)
            
            # 4. æª¢æŸ¥é©—æ”¶æ¨™æº–æ ¼å¼
            result['checks']['acceptance_criteria'] = self._check_acceptance_criteria(content)
            
            # 5. æª¢æŸ¥APIè¦æ ¼
            result['checks']['api_spec'] = self._check_api_spec(content)
            
            # 6. æª¢æŸ¥è³‡æ–™æ¨¡å‹
            result['checks']['data_model'] = self._check_data_model(content)
            
            # 7. æª¢æŸ¥æ¸¬è©¦æª”æ¡ˆå°æ‡‰
            result['checks']['test_mapping'] = self._check_test_mapping(file_path, content)
            
            # 8. æª¢æŸ¥ç‹€æ…‹æ¨™è¨˜ä¸€è‡´æ€§
            result['checks']['status_consistency'] = self._check_status_consistency(content)
            
            # è¨ˆç®—ç¸½åˆ†
            total_checks = sum(1 for check in result['checks'].values())
            passed_checks = sum(1 for check in result['checks'].values() if check['passed'])
            result['score'] = (passed_checks / total_checks * 100) if total_checks > 0 else 0
            
        except Exception as e:
            result['errors'].append(f"æª”æ¡ˆè®€å–éŒ¯èª¤: {str(e)}")
            result['score'] = 0
            
        return result
    
    def _check_module_info(self, content: str) -> Dict:
        """æª¢æŸ¥æ¨¡çµ„è³‡è¨Šå®Œæ•´æ€§"""
        check_result = {'passed': True, 'missing': [], 'details': {}}
        
        for field in self.required_fields['module_info']:
            pattern = re.compile(f'[-*]\\s*\\*\\*{field}\\*\\*\\s*[:ï¼š]\\s*(.+)', re.MULTILINE)
            match = pattern.search(content)
            
            if match:
                check_result['details'][field] = match.group(1).strip()
            else:
                check_result['passed'] = False
                check_result['missing'].append(field)
                
        # æª¢æŸ¥ç‰ˆæœ¬è™Ÿæ ¼å¼
        if 'ç‰ˆæœ¬' in check_result['details']:
            version = check_result['details']['ç‰ˆæœ¬']
            if not re.match(r'^v\d+\.\d+\.\d+$', version):
                check_result['passed'] = False
                check_result['missing'].append('ç‰ˆæœ¬è™Ÿæ ¼å¼éŒ¯èª¤(æ‡‰ç‚ºvX.X.X)')
                
        return check_result
    
    def _check_fr_ids(self, content: str) -> Dict:
        """æª¢æŸ¥FR-IDæ ¼å¼æ­£ç¢ºæ€§"""
        check_result = {'passed': True, 'invalid': [], 'duplicates': []}
        
        # æ‰¾å‡ºæ‰€æœ‰FR-ID
        fr_pattern = re.compile(r'###?\s*(FR-[A-Z0-9-]+)', re.MULTILINE)
        fr_ids = fr_pattern.findall(content)
        
        # æª¢æŸ¥æ ¼å¼
        for fr_id in fr_ids:
            if not self.fr_id_pattern.match(fr_id):
                check_result['passed'] = False
                check_result['invalid'].append(fr_id)
        
        # æª¢æŸ¥é‡è¤‡
        seen = set()
        for fr_id in fr_ids:
            if fr_id in seen:
                check_result['passed'] = False
                if fr_id not in check_result['duplicates']:
                    check_result['duplicates'].append(fr_id)
            seen.add(fr_id)
            
        check_result['total'] = len(fr_ids)
        check_result['unique'] = len(seen)
        
        return check_result
    
    def _check_fr_completeness(self, content: str) -> Dict:
        """æª¢æŸ¥åŠŸèƒ½éœ€æ±‚ä¸ƒå¤§å¿…å¡«æ¬„ä½"""
        check_result = {'passed': True, 'incomplete_frs': {}}
        
        # æ‰¾å‡ºæ‰€æœ‰FRå€å¡Š
        fr_blocks = re.split(r'###?\s*FR-[A-Z0-9-]+', content)[1:]
        fr_ids = re.findall(r'###?\s*(FR-[A-Z0-9-]+)', content)
        
        for i, (fr_id, block) in enumerate(zip(fr_ids, fr_blocks)):
            missing_fields = []
            
            for field in self.required_fields['fr_fields']:
                pattern = re.compile(f'[-*]\\s*\\*\\*{field}\\*\\*\\s*[:ï¼š]', re.MULTILINE)
                if not pattern.search(block):
                    missing_fields.append(field)
                    
            if missing_fields:
                check_result['passed'] = False
                check_result['incomplete_frs'][fr_id] = missing_fields
                
        return check_result
    
    def _check_acceptance_criteria(self, content: str) -> Dict:
        """æª¢æŸ¥é©—æ”¶æ¨™æº–YAMLæ ¼å¼"""
        check_result = {'passed': True, 'invalid_yaml': [], 'missing_ac': []}
        
        # æ‰¾å‡ºæ‰€æœ‰é©—æ”¶æ¨™æº–å€å¡Š
        ac_pattern = re.compile(
            r'\*\*é©—æ”¶æ¨™æº–\*\*.*?```yaml(.*?)```', 
            re.DOTALL | re.MULTILINE
        )
        ac_blocks = ac_pattern.findall(content)
        
        # æ‰¾å‡ºæ‰€æœ‰FR-ID
        fr_ids = re.findall(r'###?\s*(FR-[A-Z0-9-]+)', content)
        
        # æª¢æŸ¥æ¯å€‹FRæ˜¯å¦æœ‰é©—æ”¶æ¨™æº–
        if len(ac_blocks) < len(fr_ids):
            check_result['passed'] = False
            check_result['missing_ac'] = fr_ids[len(ac_blocks):]
        
        # é©—è­‰YAMLæ ¼å¼
        for i, yaml_content in enumerate(ac_blocks):
            try:
                criteria = yaml.safe_load(yaml_content)
                if not isinstance(criteria, list) or len(criteria) < 3:
                    check_result['passed'] = False
                    check_result['invalid_yaml'].append(f"FR {i+1}: éœ€è¦è‡³å°‘3å€‹é©—æ”¶æ¨™æº–")
            except yaml.YAMLError as e:
                check_result['passed'] = False
                check_result['invalid_yaml'].append(f"FR {i+1}: YAMLæ ¼å¼éŒ¯èª¤")
                
        return check_result
    
    def _check_api_spec(self, content: str) -> Dict:
        """æª¢æŸ¥APIè¦æ ¼å®Œæ•´æ€§"""
        check_result = {'passed': True, 'missing': []}
        
        # æª¢æŸ¥æ˜¯å¦æœ‰APIè¨­è¨ˆç« ç¯€
        if 'API è¨­è¨ˆ' not in content and 'APIè¨­è¨ˆ' not in content:
            check_result['passed'] = False
            check_result['missing'].append('ç¼ºå°‘APIè¨­è¨ˆç« ç¯€')
            return check_result
        
        # æª¢æŸ¥å¿…è¦çš„APIæ¬„ä½
        for field in self.required_fields['api_fields']:
            if field not in content:
                check_result['passed'] = False
                check_result['missing'].append(field)
                
        # æª¢æŸ¥æ˜¯å¦æœ‰ç«¯é»å®šç¾©
        endpoint_pattern = re.compile(r'(GET|POST|PUT|DELETE|PATCH)\s+/api/v\d+/', re.MULTILINE)
        if not endpoint_pattern.search(content):
            check_result['passed'] = False
            check_result['missing'].append('ç¼ºå°‘APIç«¯é»å®šç¾©')
            
        return check_result
    
    def _check_data_model(self, content: str) -> Dict:
        """æª¢æŸ¥è³‡æ–™æ¨¡å‹å®šç¾©"""
        check_result = {'passed': True, 'missing': []}
        
        # æª¢æŸ¥TypeScriptä»‹é¢å®šç¾©
        ts_pattern = re.compile(r'interface\s+\w+\s*{', re.MULTILINE)
        if not ts_pattern.search(content):
            check_result['passed'] = False
            check_result['missing'].append('ç¼ºå°‘TypeScriptä»‹é¢å®šç¾©')
            
        # æª¢æŸ¥SQLå»ºè¡¨èªå¥
        sql_pattern = re.compile(r'CREATE\s+TABLE\s+\w+', re.IGNORECASE | re.MULTILINE)
        if not sql_pattern.search(content):
            check_result['passed'] = False
            check_result['missing'].append('ç¼ºå°‘SQLå»ºè¡¨èªå¥')
            
        return check_result
    
    def _check_test_mapping(self, file_path: Path, content: str) -> Dict:
        """æª¢æŸ¥æ¸¬è©¦æª”æ¡ˆå°æ‡‰"""
        check_result = {'passed': True, 'missing_tests': []}
        
        # ç²å–æ¸¬è©¦ç›®éŒ„
        test_dir = file_path.parent / 'tests'
        
        # æª¢æŸ¥æ¸¬è©¦ç›®éŒ„æ˜¯å¦å­˜åœ¨
        if not test_dir.exists():
            check_result['passed'] = False
            check_result['missing_tests'].append('æ¸¬è©¦ç›®éŒ„ä¸å­˜åœ¨')
            return check_result
        
        # æª¢æŸ¥å¿…è¦çš„æ¸¬è©¦å­ç›®éŒ„
        required_test_dirs = ['unit', 'integration', 'e2e']
        for test_type in required_test_dirs:
            test_subdir = test_dir / test_type
            if not test_subdir.exists():
                check_result['passed'] = False
                check_result['missing_tests'].append(f'{test_type}æ¸¬è©¦ç›®éŒ„ä¸å­˜åœ¨')
            elif not list(test_subdir.glob('*.test.*')) and not list(test_subdir.glob('*.spec.*')):
                check_result['passed'] = False
                check_result['missing_tests'].append(f'{test_type}æ¸¬è©¦æª”æ¡ˆä¸å­˜åœ¨')
                
        return check_result
    
    def _check_status_consistency(self, content: str) -> Dict:
        """æª¢æŸ¥ç‹€æ…‹æ¨™è¨˜ä¸€è‡´æ€§"""
        check_result = {'passed': True, 'invalid_statuses': []}
        
        # æ‰¾å‡ºæ‰€æœ‰ç‹€æ…‹æ¨™è¨˜
        status_pattern = re.compile(r'\*\*ç‹€æ…‹\*\*\s*[:ï¼š]\s*([^\n]+)', re.MULTILINE)
        statuses = status_pattern.findall(content)
        
        for status in statuses:
            status = status.strip()
            # æª¢æŸ¥æ˜¯å¦ç‚ºæœ‰æ•ˆç‹€æ…‹
            if not any(valid in status for valid in self.valid_statuses):
                check_result['passed'] = False
                check_result['invalid_statuses'].append(status)
                
        return check_result
    
    def validate_all_prds(self) -> Dict:
        """é©—è­‰æ‰€æœ‰PRDæ–‡ä»¶"""
        all_results = {
            'timestamp': datetime.now().isoformat(),
            'summary': {
                'total_files': 0,
                'passed_files': 0,
                'failed_files': 0,
                'average_score': 0
            },
            'files': [],
            'errors_by_type': {},
            'recommendations': []
        }
        
        # æ‰¾å‡ºæ‰€æœ‰PRDæ–‡ä»¶
        prd_files = list(self.prd_dir.glob('**/prd.md')) + list(self.prd_dir.glob('**/README.md'))
        
        total_score = 0
        for prd_file in prd_files:
            result = self.validate_prd_file(prd_file)
            all_results['files'].append(result)
            
            total_score += result['score']
            all_results['summary']['total_files'] += 1
            
            if result['score'] == 100:
                all_results['summary']['passed_files'] += 1
            else:
                all_results['summary']['failed_files'] += 1
                
            # æ”¶é›†éŒ¯èª¤é¡å‹
            for check_name, check_result in result['checks'].items():
                if not check_result.get('passed', True):
                    if check_name not in all_results['errors_by_type']:
                        all_results['errors_by_type'][check_name] = []
                    all_results['errors_by_type'][check_name].append(result['file'])
                    
        # è¨ˆç®—å¹³å‡åˆ†
        if all_results['summary']['total_files'] > 0:
            all_results['summary']['average_score'] = total_score / all_results['summary']['total_files']
        
        # ç”Ÿæˆå»ºè­°
        all_results['recommendations'] = self._generate_recommendations(all_results)
        
        return all_results
    
    def _generate_recommendations(self, results: Dict) -> List[str]:
        """ç”Ÿæˆæ”¹é€²å»ºè­°"""
        recommendations = []
        
        if 'module_info' in results['errors_by_type']:
            recommendations.append("å„ªå…ˆå®Œå–„æ¨¡çµ„è³‡è¨Šæ¬„ä½ï¼Œç¢ºä¿ç‰ˆæœ¬è™Ÿæ ¼å¼æ­£ç¢º(vX.X.X)")
            
        if 'fr_ids' in results['errors_by_type']:
            recommendations.append("æª¢æŸ¥ä¸¦ä¿®æ­£FR-IDæ ¼å¼ï¼Œç¢ºä¿ç¬¦åˆFR-[æ¨¡çµ„]-[å­æ¨¡çµ„]-[åºè™Ÿ]æ ¼å¼")
            
        if 'fr_completeness' in results['errors_by_type']:
            recommendations.append("è£œå……åŠŸèƒ½éœ€æ±‚çš„ä¸ƒå¤§å¿…å¡«æ¬„ä½ï¼Œç‰¹åˆ¥æ³¨æ„æ¢ä»¶/è§¸ç™¼å’Œä¾‹å¤–è™•ç†")
            
        if 'acceptance_criteria' in results['errors_by_type']:
            recommendations.append("ä½¿ç”¨YAMLæ ¼å¼æ’°å¯«é©—æ”¶æ¨™æº–ï¼Œæ¯å€‹FRè‡³å°‘åŒ…å«3å€‹é©—æ”¶æ¢ä»¶")
            
        if 'api_spec' in results['errors_by_type']:
            recommendations.append("å®Œå–„APIè¦æ ¼å®šç¾©ï¼ŒåŒ…å«ç«¯é»ã€è«‹æ±‚/å›æ‡‰æ ¼å¼å’Œèªè­‰æ–¹å¼")
            
        if 'data_model' in results['errors_by_type']:
            recommendations.append("æ·»åŠ TypeScriptä»‹é¢å®šç¾©å’ŒSQLå»ºè¡¨èªå¥")
            
        if 'test_mapping' in results['errors_by_type']:
            recommendations.append("å‰µå»ºå°æ‡‰çš„æ¸¬è©¦ç›®éŒ„çµæ§‹(unit/integration/e2e)")
            
        return recommendations
    
    def generate_report(self, results: Dict, output_format: str = 'markdown') -> str:
        """ç”Ÿæˆé©—è­‰å ±å‘Š"""
        if output_format == 'markdown':
            return self._generate_markdown_report(results)
        elif output_format == 'json':
            return json.dumps(results, indent=2, ensure_ascii=False)
        else:
            raise ValueError(f"ä¸æ”¯æ´çš„è¼¸å‡ºæ ¼å¼: {output_format}")
            
    def _generate_markdown_report(self, results: Dict) -> str:
        """ç”ŸæˆMarkdownæ ¼å¼å ±å‘Š"""
        report = []
        report.append(f"# PRDå“è³ªé©—è­‰å ±å‘Š")
        report.append(f"\n**é©—è­‰æ™‚é–“**: {results['timestamp']}")
        report.append(f"\n## ğŸ“Š ç¸½é«”çµ±è¨ˆ\n")
        
        summary = results['summary']
        report.append(f"- **æª¢æŸ¥æª”æ¡ˆæ•¸**: {summary['total_files']}")
        report.append(f"- **é€šéæª”æ¡ˆæ•¸**: {summary['passed_files']} ({summary['passed_files']/max(1,summary['total_files'])*100:.1f}%)")
        report.append(f"- **å¤±æ•—æª”æ¡ˆæ•¸**: {summary['failed_files']}")
        report.append(f"- **å¹³å‡åˆ†æ•¸**: {summary['average_score']:.1f}/100")
        
        # éŒ¯èª¤é¡å‹çµ±è¨ˆ
        if results['errors_by_type']:
            report.append(f"\n## âŒ éŒ¯èª¤é¡å‹åˆ†æ\n")
            for error_type, files in results['errors_by_type'].items():
                report.append(f"\n### {error_type}")
                report.append(f"å—å½±éŸ¿æª”æ¡ˆæ•¸: {len(files)}")
                for file in files[:5]:  # åªé¡¯ç¤ºå‰5å€‹
                    report.append(f"- {file}")
                if len(files) > 5:
                    report.append(f"- ...é‚„æœ‰{len(files)-5}å€‹æª”æ¡ˆ")
                    
        # æª”æ¡ˆè©³æƒ…
        report.append(f"\n## ğŸ“ æª”æ¡ˆè©³æƒ…\n")
        
        # å…ˆé¡¯ç¤ºå¤±æ•—çš„æª”æ¡ˆ
        failed_files = [f for f in results['files'] if f['score'] < 100]
        if failed_files:
            report.append(f"\n### éœ€è¦ä¿®æ­£çš„æª”æ¡ˆ\n")
            for file_result in failed_files[:10]:  # åªé¡¯ç¤ºå‰10å€‹
                report.append(f"\n#### {file_result['file']}")
                report.append(f"- **åˆ†æ•¸**: {file_result['score']:.1f}/100")
                report.append(f"- **å•é¡Œ**:")
                
                for check_name, check_result in file_result['checks'].items():
                    if not check_result.get('passed', True):
                        report.append(f"  - âŒ {check_name}")
                        if 'missing' in check_result:
                            report.append(f"    - ç¼ºå°‘: {', '.join(check_result['missing'])}")
                        if 'invalid' in check_result:
                            report.append(f"    - ç„¡æ•ˆ: {', '.join(check_result['invalid'])}")
                            
        # å»ºè­°
        if results['recommendations']:
            report.append(f"\n## ğŸ’¡ æ”¹é€²å»ºè­°\n")
            for i, rec in enumerate(results['recommendations'], 1):
                report.append(f"{i}. {rec}")
                
        # æˆåŠŸçš„æª”æ¡ˆ
        passed_files = [f for f in results['files'] if f['score'] == 100]
        if passed_files:
            report.append(f"\n## âœ… åˆæ ¼æª”æ¡ˆ ({len(passed_files)}å€‹)\n")
            for file_result in passed_files[:20]:  # åªé¡¯ç¤ºå‰20å€‹
                report.append(f"- {file_result['file']}")
                
        return '\n'.join(report)
    
def main():
    """ä¸»å‡½æ•¸"""
    import argparse
    
    parser = argparse.ArgumentParser(description='PRDå“è³ªé©—è­‰å·¥å…·')
    parser.add_argument('--dir', default='PRD', help='PRDç›®éŒ„è·¯å¾‘')
    parser.add_argument('--output', default='markdown', choices=['markdown', 'json'], help='è¼¸å‡ºæ ¼å¼')
    parser.add_argument('--file', help='é©—è­‰å–®å€‹æª”æ¡ˆ')
    parser.add_argument('--save', help='å„²å­˜å ±å‘Šåˆ°æª”æ¡ˆ')
    
    args = parser.parse_args()
    
    validator = PRDValidator(args.dir)
    
    if args.file:
        # é©—è­‰å–®å€‹æª”æ¡ˆ
        result = validator.validate_prd_file(Path(args.file))
        results = {
            'timestamp': datetime.now().isoformat(),
            'summary': {
                'total_files': 1,
                'passed_files': 1 if result['score'] == 100 else 0,
                'failed_files': 0 if result['score'] == 100 else 1,
                'average_score': result['score']
            },
            'files': [result],
            'errors_by_type': {},
            'recommendations': []
        }
    else:
        # é©—è­‰æ‰€æœ‰æª”æ¡ˆ
        results = validator.validate_all_prds()
        
    # ç”Ÿæˆå ±å‘Š
    report = validator.generate_report(results, args.output)
    
    # è¼¸å‡ºæˆ–å„²å­˜å ±å‘Š
    if args.save:
        with open(args.save, 'w', encoding='utf-8') as f:
            f.write(report)
        print(f"å ±å‘Šå·²å„²å­˜åˆ°: {args.save}")
    else:
        print(report)
        
    # è¿”å›é€€å‡ºç¢¼
    if results['summary']['failed_files'] > 0:
        sys.exit(1)
    else:
        sys.exit(0)

if __name__ == '__main__':
    main()